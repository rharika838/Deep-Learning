{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoEncoders.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"10QfOZLYC85Q3LgF5f7gJ6g5nhv9mH6bL","authorship_tag":"ABX9TyOCgs1gOsdnx/MvtGkflAKo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# AutoEncoders"],"metadata":{"id":"PsGx-XPl-88D"}},{"cell_type":"markdown","source":["## Downloading the dataset"],"metadata":{"id":"TucmARjj_D0N"}},{"cell_type":"markdown","source":["### ML-100K"],"metadata":{"id":"H2L6uGrx_HTC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yGNimi5gB_A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645006475042,"user_tz":-330,"elapsed":1391,"user":{"displayName":"Chebolu Ratna Harika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOWAF8THPa011V76S1xLFXAjtj0Y4WMP7p6PP41Q=s64","userId":"08850792314618797682"}},"outputId":"86c5be77-cf87-4336-cf5f-f4f53c83236a"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-16 10:14:33--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4924029 (4.7M) [application/zip]\n","Saving to: ‘ml-100k.zip’\n","\n","ml-100k.zip         100%[===================>]   4.70M  11.2MB/s    in 0.4s    \n","\n","2022-02-16 10:14:34 (11.2 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n","\n","Archive:  ml-100k.zip\n","   creating: ml-100k/\n","  inflating: ml-100k/allbut.pl       \n","  inflating: ml-100k/mku.sh          \n","  inflating: ml-100k/README          \n","  inflating: ml-100k/u.data          \n","  inflating: ml-100k/u.genre         \n","  inflating: ml-100k/u.info          \n","  inflating: ml-100k/u.item          \n","  inflating: ml-100k/u.occupation    \n","  inflating: ml-100k/u.user          \n","  inflating: ml-100k/u1.base         \n","  inflating: ml-100k/u1.test         \n","  inflating: ml-100k/u2.base         \n","  inflating: ml-100k/u2.test         \n","  inflating: ml-100k/u3.base         \n","  inflating: ml-100k/u3.test         \n","  inflating: ml-100k/u4.base         \n","  inflating: ml-100k/u4.test         \n","  inflating: ml-100k/u5.base         \n","  inflating: ml-100k/u5.test         \n","  inflating: ml-100k/ua.base         \n","  inflating: ml-100k/ua.test         \n","  inflating: ml-100k/ub.base         \n","  inflating: ml-100k/ub.test         \n","drive  ml-100k\tml-100k.zip  sample_data\n"]}],"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n","!unzip ml-100k.zip\n","!ls"]},{"cell_type":"markdown","source":["### ML-1M"],"metadata":{"id":"5aGEXno5ARp0"}},{"cell_type":"code","source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n","!unzip ml-1m.zip\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTVgQNa8APde","executionInfo":{"status":"ok","timestamp":1645006477013,"user_tz":-330,"elapsed":1982,"user":{"displayName":"Chebolu Ratna Harika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOWAF8THPa011V76S1xLFXAjtj0Y4WMP7p6PP41Q=s64","userId":"08850792314618797682"}},"outputId":"0e963b79-4935-431c-89bb-6210bcc666f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-16 10:14:34--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5917549 (5.6M) [application/zip]\n","Saving to: ‘ml-1m.zip’\n","\n","ml-1m.zip           100%[===================>]   5.64M  13.3MB/s    in 0.4s    \n","\n","2022-02-16 10:14:35 (13.3 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n","\n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n","drive  ml-100k\tml-100k.zip  ml-1m  ml-1m.zip  sample_data\n"]}]},{"cell_type":"markdown","source":["### Importing the libraries"],"metadata":{"id":"a-7vN-0yAVti"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"metadata":{"id":"Z2M34zisAbyA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Importing the dataset"],"metadata":{"id":"WMOSVKBYAd7p"}},{"cell_type":"code","source":["# We won't be using this dataset.\n","movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"metadata":{"id":"O09zEtRmAiBB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  Preparing the training set and the test set"],"metadata":{"id":"i-6UKKqtAkII"}},{"cell_type":"code","source":["training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')"],"metadata":{"id":"ZXohs6gHAoP6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Getting the number of users and movies"],"metadata":{"id":"RcRN8UOyArSD"}},{"cell_type":"code","source":["nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n","nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"],"metadata":{"id":"taZ97SVDBOPh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Converting the data into an array with users in lines and movies in columns"],"metadata":{"id":"AeNnqdkhBQ0Y"}},{"cell_type":"code","source":["def convert(data):\n","  new_data = []\n","  for id_users in range(1, nb_users + 1):\n","    id_movies = data[:, 1] [data[:, 0] == id_users]\n","    id_ratings = data[:, 2] [data[:, 0] == id_users]\n","    ratings = np.zeros(nb_movies)\n","    ratings[id_movies - 1] = id_ratings\n","    new_data.append(list(ratings))\n","  return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"metadata":{"id":"2-SidTLHBT9b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Converting the data into Torch tensors"],"metadata":{"id":"gCEGa7sPBWtg"}},{"cell_type":"code","source":["training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"metadata":{"id":"Xznz-ch6BZOn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating the architecture of the Neural Network"],"metadata":{"id":"JDrQzh2qBbBn"}},{"cell_type":"code","source":["class SAE(nn.Module):\n","    #this is a Stacked AutoEncoder\n","    def __init__(self, ):\n","        super(SAE, self).__init__()   #super lets us use methods and classes of nn module\n","        self.fc1 = nn.Linear(nb_movies, 20)    \n","        self.fc2 = nn.Linear(20, 10)           \n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self, x):     \n","        #not only will help in encoding and decoding but also will apply to different activation functions inside the fc\n","        #this function also returns a vector of predicted ratings that we'll compare to the real ratings (input vector) \n","        x = self.activation(self.fc1(x))  #returns 1st encoded vector\n","        x = self.activation(self.fc2(x))  #returns 2nd encoded vector\n","        x = self.activation(self.fc3(x))  #returns decoded vector\n","        x = self.fc4(x)                   #last part of decoding so we use the last layer without activation function\n","        return x      #vector of predicted ratings\n","sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5) #lr: learning rate, weight_decay helps in convergence"],"metadata":{"id":"Nh6G7sRcBdMb","executionInfo":{"status":"ok","timestamp":1645009183165,"user_tz":-330,"elapsed":414,"user":{"displayName":"Chebolu Ratna Harika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOWAF8THPa011V76S1xLFXAjtj0Y4WMP7p6PP41Q=s64","userId":"08850792314618797682"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Training the SAE"],"metadata":{"id":"DFHzifroBhBC"}},{"cell_type":"code","source":["nb_epoch = 200\n","for epoch in range(1, nb_epoch + 1):\n","  train_loss = 0\n","  s = 0.\n","  for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = input.clone()\n","    if torch.sum(target.data > 0) > 0:\n","      output = sae(input)\n","      target.require_grad = False\n","      output[target == 0] = 0\n","      loss = criterion(output, target)\n","      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","      loss.backward()\n","      train_loss += np.sqrt(loss.data*mean_corrector)\n","      s += 1.\n","      optimizer.step()\n","  print('epoch: '+str(epoch)+' loss: '+ str(train_loss/s))"],"metadata":{"id":"pjS3B0JnBiCF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645010523732,"user_tz":-330,"elapsed":269239,"user":{"displayName":"Chebolu Ratna Harika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOWAF8THPa011V76S1xLFXAjtj0Y4WMP7p6PP41Q=s64","userId":"08850792314618797682"}},"outputId":"6954eaa3-9949-40d5-cce5-8cdc237463b4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1 loss: tensor(1.0184)\n","epoch: 2 loss: tensor(1.0179)\n","epoch: 3 loss: tensor(1.0174)\n","epoch: 4 loss: tensor(1.0172)\n","epoch: 5 loss: tensor(1.0169)\n","epoch: 6 loss: tensor(1.0165)\n","epoch: 7 loss: tensor(1.0166)\n","epoch: 8 loss: tensor(1.0160)\n","epoch: 9 loss: tensor(1.0162)\n","epoch: 10 loss: tensor(1.0160)\n","epoch: 11 loss: tensor(1.0159)\n","epoch: 12 loss: tensor(1.0157)\n","epoch: 13 loss: tensor(1.0159)\n","epoch: 14 loss: tensor(1.0156)\n","epoch: 15 loss: tensor(1.0156)\n","epoch: 16 loss: tensor(1.0151)\n","epoch: 17 loss: tensor(1.0152)\n","epoch: 18 loss: tensor(1.0126)\n","epoch: 19 loss: tensor(1.0114)\n","epoch: 20 loss: tensor(1.0103)\n","epoch: 21 loss: tensor(1.0079)\n","epoch: 22 loss: tensor(1.0072)\n","epoch: 23 loss: tensor(1.0040)\n","epoch: 24 loss: tensor(1.0023)\n","epoch: 25 loss: tensor(1.0004)\n","epoch: 26 loss: tensor(0.9983)\n","epoch: 27 loss: tensor(0.9957)\n","epoch: 28 loss: tensor(0.9947)\n","epoch: 29 loss: tensor(0.9894)\n","epoch: 30 loss: tensor(0.9892)\n","epoch: 31 loss: tensor(0.9855)\n","epoch: 32 loss: tensor(0.9849)\n","epoch: 33 loss: tensor(0.9837)\n","epoch: 34 loss: tensor(0.9854)\n","epoch: 35 loss: tensor(0.9876)\n","epoch: 36 loss: tensor(0.9859)\n","epoch: 37 loss: tensor(0.9824)\n","epoch: 38 loss: tensor(0.9793)\n","epoch: 39 loss: tensor(0.9779)\n","epoch: 40 loss: tensor(0.9822)\n","epoch: 41 loss: tensor(0.9776)\n","epoch: 42 loss: tensor(0.9810)\n","epoch: 43 loss: tensor(0.9750)\n","epoch: 44 loss: tensor(0.9729)\n","epoch: 45 loss: tensor(0.9676)\n","epoch: 46 loss: tensor(0.9687)\n","epoch: 47 loss: tensor(0.9647)\n","epoch: 48 loss: tensor(0.9656)\n","epoch: 49 loss: tensor(0.9629)\n","epoch: 50 loss: tensor(0.9625)\n","epoch: 51 loss: tensor(0.9618)\n","epoch: 52 loss: tensor(0.9617)\n","epoch: 53 loss: tensor(0.9598)\n","epoch: 54 loss: tensor(0.9592)\n","epoch: 55 loss: tensor(0.9564)\n","epoch: 56 loss: tensor(0.9560)\n","epoch: 57 loss: tensor(0.9519)\n","epoch: 58 loss: tensor(0.9564)\n","epoch: 59 loss: tensor(0.9529)\n","epoch: 60 loss: tensor(0.9521)\n","epoch: 61 loss: tensor(0.9496)\n","epoch: 62 loss: tensor(0.9521)\n","epoch: 63 loss: tensor(0.9523)\n","epoch: 64 loss: tensor(0.9518)\n","epoch: 65 loss: tensor(0.9511)\n","epoch: 66 loss: tensor(0.9479)\n","epoch: 67 loss: tensor(0.9488)\n","epoch: 68 loss: tensor(0.9475)\n","epoch: 69 loss: tensor(0.9470)\n","epoch: 70 loss: tensor(0.9453)\n","epoch: 71 loss: tensor(0.9440)\n","epoch: 72 loss: tensor(0.9444)\n","epoch: 73 loss: tensor(0.9438)\n","epoch: 74 loss: tensor(0.9448)\n","epoch: 75 loss: tensor(0.9429)\n","epoch: 76 loss: tensor(0.9434)\n","epoch: 77 loss: tensor(0.9414)\n","epoch: 78 loss: tensor(0.9423)\n","epoch: 79 loss: tensor(0.9404)\n","epoch: 80 loss: tensor(0.9409)\n","epoch: 81 loss: tensor(0.9400)\n","epoch: 82 loss: tensor(0.9398)\n","epoch: 83 loss: tensor(0.9389)\n","epoch: 84 loss: tensor(0.9388)\n","epoch: 85 loss: tensor(0.9375)\n","epoch: 86 loss: tensor(0.9376)\n","epoch: 87 loss: tensor(0.9375)\n","epoch: 88 loss: tensor(0.9372)\n","epoch: 89 loss: tensor(0.9372)\n","epoch: 90 loss: tensor(0.9366)\n","epoch: 91 loss: tensor(0.9370)\n","epoch: 92 loss: tensor(0.9366)\n","epoch: 93 loss: tensor(0.9355)\n","epoch: 94 loss: tensor(0.9355)\n","epoch: 95 loss: tensor(0.9359)\n","epoch: 96 loss: tensor(0.9358)\n","epoch: 97 loss: tensor(0.9356)\n","epoch: 98 loss: tensor(0.9351)\n","epoch: 99 loss: tensor(0.9351)\n","epoch: 100 loss: tensor(0.9345)\n","epoch: 101 loss: tensor(0.9340)\n","epoch: 102 loss: tensor(0.9338)\n","epoch: 103 loss: tensor(0.9332)\n","epoch: 104 loss: tensor(0.9335)\n","epoch: 105 loss: tensor(0.9335)\n","epoch: 106 loss: tensor(0.9333)\n","epoch: 107 loss: tensor(0.9327)\n","epoch: 108 loss: tensor(0.9329)\n","epoch: 109 loss: tensor(0.9324)\n","epoch: 110 loss: tensor(0.9322)\n","epoch: 111 loss: tensor(0.9324)\n","epoch: 112 loss: tensor(0.9319)\n","epoch: 113 loss: tensor(0.9315)\n","epoch: 114 loss: tensor(0.9315)\n","epoch: 115 loss: tensor(0.9310)\n","epoch: 116 loss: tensor(0.9308)\n","epoch: 117 loss: tensor(0.9300)\n","epoch: 118 loss: tensor(0.9302)\n","epoch: 119 loss: tensor(0.9295)\n","epoch: 120 loss: tensor(0.9297)\n","epoch: 121 loss: tensor(0.9291)\n","epoch: 122 loss: tensor(0.9296)\n","epoch: 123 loss: tensor(0.9293)\n","epoch: 124 loss: tensor(0.9291)\n","epoch: 125 loss: tensor(0.9284)\n","epoch: 126 loss: tensor(0.9291)\n","epoch: 127 loss: tensor(0.9280)\n","epoch: 128 loss: tensor(0.9282)\n","epoch: 129 loss: tensor(0.9283)\n","epoch: 130 loss: tensor(0.9332)\n","epoch: 131 loss: tensor(0.9286)\n","epoch: 132 loss: tensor(0.9276)\n","epoch: 133 loss: tensor(0.9268)\n","epoch: 134 loss: tensor(0.9265)\n","epoch: 135 loss: tensor(0.9264)\n","epoch: 136 loss: tensor(0.9264)\n","epoch: 137 loss: tensor(0.9255)\n","epoch: 138 loss: tensor(0.9258)\n","epoch: 139 loss: tensor(0.9249)\n","epoch: 140 loss: tensor(0.9253)\n","epoch: 141 loss: tensor(0.9245)\n","epoch: 142 loss: tensor(0.9244)\n","epoch: 143 loss: tensor(0.9235)\n","epoch: 144 loss: tensor(0.9238)\n","epoch: 145 loss: tensor(0.9239)\n","epoch: 146 loss: tensor(0.9240)\n","epoch: 147 loss: tensor(0.9228)\n","epoch: 148 loss: tensor(0.9238)\n","epoch: 149 loss: tensor(0.9225)\n","epoch: 150 loss: tensor(0.9231)\n","epoch: 151 loss: tensor(0.9222)\n","epoch: 152 loss: tensor(0.9224)\n","epoch: 153 loss: tensor(0.9213)\n","epoch: 154 loss: tensor(0.9218)\n","epoch: 155 loss: tensor(0.9216)\n","epoch: 156 loss: tensor(0.9223)\n","epoch: 157 loss: tensor(0.9214)\n","epoch: 158 loss: tensor(0.9211)\n","epoch: 159 loss: tensor(0.9211)\n","epoch: 160 loss: tensor(0.9218)\n","epoch: 161 loss: tensor(0.9203)\n","epoch: 162 loss: tensor(0.9219)\n","epoch: 163 loss: tensor(0.9203)\n","epoch: 164 loss: tensor(0.9214)\n","epoch: 165 loss: tensor(0.9201)\n","epoch: 166 loss: tensor(0.9206)\n","epoch: 167 loss: tensor(0.9197)\n","epoch: 168 loss: tensor(0.9201)\n","epoch: 169 loss: tensor(0.9196)\n","epoch: 170 loss: tensor(0.9200)\n","epoch: 171 loss: tensor(0.9189)\n","epoch: 172 loss: tensor(0.9191)\n","epoch: 173 loss: tensor(0.9189)\n","epoch: 174 loss: tensor(0.9196)\n","epoch: 175 loss: tensor(0.9184)\n","epoch: 176 loss: tensor(0.9189)\n","epoch: 177 loss: tensor(0.9178)\n","epoch: 178 loss: tensor(0.9192)\n","epoch: 179 loss: tensor(0.9182)\n","epoch: 180 loss: tensor(0.9184)\n","epoch: 181 loss: tensor(0.9173)\n","epoch: 182 loss: tensor(0.9182)\n","epoch: 183 loss: tensor(0.9180)\n","epoch: 184 loss: tensor(0.9181)\n","epoch: 185 loss: tensor(0.9175)\n","epoch: 186 loss: tensor(0.9180)\n","epoch: 187 loss: tensor(0.9175)\n","epoch: 188 loss: tensor(0.9172)\n","epoch: 189 loss: tensor(0.9165)\n","epoch: 190 loss: tensor(0.9169)\n","epoch: 191 loss: tensor(0.9163)\n","epoch: 192 loss: tensor(0.9172)\n","epoch: 193 loss: tensor(0.9163)\n","epoch: 194 loss: tensor(0.9169)\n","epoch: 195 loss: tensor(0.9165)\n","epoch: 196 loss: tensor(0.9166)\n","epoch: 197 loss: tensor(0.9153)\n","epoch: 198 loss: tensor(0.9162)\n","epoch: 199 loss: tensor(0.9158)\n","epoch: 200 loss: tensor(0.9162)\n"]}]},{"cell_type":"markdown","source":["### Testing the SAE"],"metadata":{"id":"UuHhmwgGBmuE"}},{"cell_type":"code","source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","  input = Variable(training_set[id_user]).unsqueeze(0)\n","  target = Variable(test_set[id_user]).unsqueeze(0)\n","  if torch.sum(target.data > 0) > 0:\n","    output = sae(input)\n","    target.require_grad = False\n","    output[target == 0] = 0\n","    loss = criterion(output, target)\n","    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","    test_loss += np.sqrt(loss.data*mean_corrector)\n","    s += 1.\n","print('test loss: '+str(test_loss/s))"],"metadata":{"id":"hmnqaNhfBnhJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645010827163,"user_tz":-330,"elapsed":700,"user":{"displayName":"Chebolu Ratna Harika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOWAF8THPa011V76S1xLFXAjtj0Y4WMP7p6PP41Q=s64","userId":"08850792314618797682"}},"outputId":"15be50bb-b4e2-4edb-a037-de933da96d23"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["test loss: tensor(0.9755)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"_u0TeDDLSTGU"},"execution_count":null,"outputs":[]}]}